###### ê¸°ë³¸ ì •ë³´ ì„¤ì • ë‹¨ê³„ #######
from fastapi import Request, FastAPI
import openai
import threading
import time
import queue as q
import os


from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain.vectorstores.chroma import Chroma
import streamlit as st
import time
from langchain.document_loaders import PyPDFLoader
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.agents.agent_toolkits import create_retriever_tool
from langchain.chat_models import ChatOpenAI
from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (
    AgentTokenBufferMemory,
)

from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.agents.conversational_chat.base import ConversationalChatAgent
from langchain.schema.messages import SystemMessage
from langchain.prompts import MessagesPlaceholder
from langchain.agents import AgentExecutor
from langchain.memory import ConversationBufferMemory

from loader import Loader_Rag , Loader_Voc

##################
FLAG_RAG = False
FLAG_VOC = True
Cause_list = 0
##################

if FLAG_RAG: 
    # ChatGPTì—”ì§„ ë©”ëª¨ë¦¬ í• ë‹¹
    loader_mem = Loader_Rag()
    loader_mem.load_all()

if FLAG_VOC:
    loader_mem = Loader_Voc()
    loader_mem.load_all()

# OpenAI API KEY
API_KEY = "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"
# client = openai.OpenAI(api_key = API_KEY)


###### ì„œë²„ ìƒì„± ë‹¨ê³„ #######
app = FastAPI()

@app.get("/")
async def root():
    return {"message": "kakaoTest"}

@app.post("/chat/")
async def chat(request: Request):
    kakaorequest = await request.json()
    # print(kakaorequest)
    # return
    return mainChat(kakaorequest)



###### ì¹´ì¹´ì˜¤í†¡ ì‘ë‹µ í•¨ìˆ˜ ######
# ë©”ì„¸ì§€ ì „ì†¡
def textResponseFormat(bot_response):
    response = {'version': '2.0', 'template': {
    'outputs': [{"simpleText": {"text": bot_response}}], 'quickReplies': []}}
    return response

# ì‘ë‹µ ì´ˆê³¼ì‹œ ë‹µë³€
def timeover():
    response = {"version":"2.0","template":{
      "outputs":[
         {
            "simpleText":{
               "text":"ì•„ì§ ì œê°€ ìƒê°ì´ ëë‚˜ì§€ ì•Šì•˜ì–´ìš”ğŸ™ğŸ™\nì ì‹œí›„ ì•„ë˜ ë§í’ì„ ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”ğŸ‘†"
            }
         }
      ],
      "quickReplies":[
         {
            "action":"message",
            "label":"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?ğŸ™‹",
            "messageText":"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?"
         }]}}
    return response

# í…ìŠ¤íŠ¸íŒŒì¼ ì´ˆê¸°í™”
def dbReset(filename):
    with open(filename, 'w') as f:
        f.write("")


# ChatGPTì—ê²Œ ì§ˆë¬¸/ë‹µë³€ ë°›ê¸° #yna: ì´ê±¸ ìƒí ì „ì„ë‹˜ ì½”ë“œë¡œ ìˆ˜ì •í•´ì•¼í•¨
def getTextFromGPT(messages):
    message = loader_mem.chagwithGPT(messages)
    return message

def getCauseFromGPT(messages):
    Cause_list = loader_mem.find_cause(messages)
    return Cause_list

###### ë©”ì¸ í•¨ìˆ˜ ë‹¨ê³„ #######

# ë©”ì¸ í•¨ìˆ˜
def mainChat(kakaorequest):

    run_flag = False
    start_time = time.time()

    # ì‘ë‹µ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    cwd = os.getcwd()
    filename = cwd + '/botlog.txt'
    if not os.path.exists(filename):
        with open(filename, "w") as f:
            f.write("")
    else:
        print("File Exists")    

    # ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰
    response_queue = q.Queue()
    request_respond = threading.Thread(target=responseOpenAI,
                                        args=(kakaorequest, response_queue,filename))
    request_respond.start()

    # ë‹µë³€ ìƒì„± ì‹œê°„ ì²´í¬
    while (time.time() - start_time < 3.5):
        if not response_queue.empty():
            # 3.5ì´ˆ ì•ˆì— ë‹µë³€ì´ ì™„ì„±ë˜ë©´ ë°”ë¡œ ê°’ ë¦¬í„´
            response = response_queue.get()
            run_flag= True
            break
        # ì•ˆì •ì ì¸ êµ¬ë™ì„ ìœ„í•œ ë”œë ˆì´ íƒ€ì„ ì„¤ì •
        time.sleep(0.01)

    # 3.5ì´ˆ ë‚´ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš°
    if run_flag== False:     
        response = timeover()

    return response


# ë‹µë³€/ì‚¬ì§„ ìš”ì²­ ë° ì‘ë‹µ í™•ì¸ í•¨ìˆ˜
def responseOpenAI(request,response_queue,filename):
    
    if FLAG_VOC:

        # ì‚¬ìš©ìë‹¤ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹µë³€ ì™„ì„± ì—¬ë¶€ë¥¼ ë‹¤ì‹œ ë´¤ì„ ì‹œ
        if 'ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?' in request["userRequest"]["utterance"]:
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°
            with open(filename) as f:
                last_update = f.read()
            # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ ì €ì¥ëœ ì •ë³´ê°€ ìˆì„ ê²½ìš°
            if len(last_update.split())>1:
                kind = last_update.split()[0]  
                if kind == "img":
                    print("kkk")
                else:
                    bot_res = last_update[4:]
                    response_queue.put(textResponseFormat(bot_res))
                dbReset(filename)

            
        #ChatGPT ë‹µë³€ì„ ìš”ì²­í•œ ê²½ìš°
        else:
            dbReset(filename)

            #VOC ë¬¸ì˜ ì²« ë©”ì„¸ì§€ - ì›ì¸ ë¶„ì„
            if len(Cause_list)==0: 
            # if 'ë¬¸ì˜' in request["userRequest"]["utterance"]:
                Cause_list = getCauseFromGPT(request["userRequest"]["utterance"])
                bot_res = Loader_Voc.findCausewithGPT(Cause_list, 0)
                response_queue.put(textResponseFormat(bot_res))
                index = 1
            
            else:
                bot_res = Loader_Voc.findCausewithGPT(Cause_list, index)
                response_queue.put(textResponseFormat(bot_res))
                index += 1

                # bot_res = getTextFromGPT(request["userRequest"]["utterance"])
                # response_queue.put(textResponseFormat(bot_res))

                # save_log = "ask"+ " " + str(bot_res)
                # with open(filename, 'w') as f:
                #     f.write(save_log)

    if FLAG_RAG:
        # ì‚¬ìš©ìë‹¤ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹µë³€ ì™„ì„± ì—¬ë¶€ë¥¼ ë‹¤ì‹œ ë´¤ì„ ì‹œ
        if 'ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?' in request["userRequest"]["utterance"]:
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°
            with open(filename) as f:
                last_update = f.read()
            # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ ì €ì¥ëœ ì •ë³´ê°€ ìˆì„ ê²½ìš°
            if len(last_update.split())>1:
                kind = last_update.split()[0]  
                if kind == "img":
                    print("kkk")
                else:
                    bot_res = last_update[4:]
                    response_queue.put(textResponseFormat(bot_res))
                dbReset(filename)

            
        #ChatGPT ë‹µë³€ì„ ìš”ì²­í•œ ê²½ìš°
        else:
            # # ê¸°ë³¸ response ê°’
            # base_response = {'version': '2.0', 'template': {'outputs': [], 'quickReplies': []}}
            # response_queue.put(base_response)
            dbReset(filename)

            bot_res = getTextFromGPT(request["userRequest"]["utterance"])
            response_queue.put(textResponseFormat(bot_res))

            save_log = "ask"+ " " + str(bot_res)
            with open(filename, 'w') as f:
                f.write(save_log)