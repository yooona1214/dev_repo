###### ê¸°ë³¸ ì •ë³´ ì„¤ì • ë‹¨ê³„ #######
from fastapi import Request, FastAPI
import openai
import threading
import time
import queue as q
import os


from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain.vectorstores.chroma import Chroma
import streamlit as st
import time
from langchain.document_loaders import PyPDFLoader
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.agents.agent_toolkits import create_retriever_tool
from langchain.chat_models import ChatOpenAI
from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (
    AgentTokenBufferMemory,
)

from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.agents.conversational_chat.base import ConversationalChatAgent
from langchain.schema.messages import SystemMessage
from langchain.prompts import MessagesPlaceholder
from langchain.agents import AgentExecutor
from langchain.memory import ConversationBufferMemory

from loader import Loader

# ChatGPTì—”ì§„ ë©”ëª¨ë¦¬ í• ë‹¹
loader_mem = Loader()
loader_mem.load_all()

# OpenAI API KEY
API_KEY = "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"
# client = openai.OpenAI(api_key = API_KEY)


###### ì„œë²„ ìƒì„± ë‹¨ê³„ #######
app = FastAPI()

@app.get("/")
async def root():
    return {"message": "kakaoTest"}

@app.post("/chat/")
async def chat(request: Request):
    kakaorequest = await request.json()
    # print(kakaorequest)
    # return
    return mainChat(kakaorequest)


# ë©”ì„¸ì§€ ì „ì†¡
def textResponseFormat(bot_response):
    response = {'version': '2.0', 'template': {
    'outputs': [{"simpleText": {"text": bot_response}}], 'quickReplies': []}}
    return response

# ì‘ë‹µ ì´ˆê³¼ì‹œ ë‹µë³€
def timeover():
    response = {"version":"2.0","template":{
      "outputs":[
         {
            "simpleText":{
               "text":"ì•„ì§ ì œê°€ ìƒê°ì´ ëë‚˜ì§€ ì•Šì•˜ì–´ìš”ğŸ™ğŸ™\nì ì‹œí›„ ì•„ë˜ ë§í’ì„ ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”ğŸ‘†"
            }
         }
      ],
      "quickReplies":[
         {
            "action":"message",
            "label":"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?ğŸ™‹",
            "messageText":"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?"
         }]}}
    return response

# í…ìŠ¤íŠ¸íŒŒì¼ ì´ˆê¸°í™”
def dbReset(filename):
    with open(filename, 'w') as f:
        f.write("")


# ChatGPTì—ê²Œ ì§ˆë¬¸/ë‹µë³€ ë°›ê¸° #yna: ì´ê±¸ ìƒí ì „ì„ë‹˜ ì½”ë“œë¡œ ìˆ˜ì •í•´ì•¼í•¨
def getTextFromGPT(messages):
    # messages_prompt = [{"role": "system", "content": 'You are a thoughtful assistant. Respond to all input in 25 words and answer in korea'}]
    # messages_prompt += [{"role": "user", "content": messages}]
    # response = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages_prompt)
    # message = response.choices[0].message.content

    message = loader_mem.chatwithGPT(messages)

    return message


###### ë©”ì¸ í•¨ìˆ˜ ë‹¨ê³„ #######

# ë©”ì¸ í•¨ìˆ˜
def mainChat(kakaorequest):

    run_flag = False
    start_time = time.time()

    # ì‘ë‹µ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    cwd = os.getcwd()
    filename = cwd + '/botlog.txt'
    if not os.path.exists(filename):
        with open(filename, "w") as f:
            f.write("")
    else:
        print("File Exists")    

    # ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰
    response_queue = q.Queue()
    request_respond = threading.Thread(target=responseOpenAI,
                                        args=(kakaorequest, response_queue,filename))
    request_respond.start()

    # ë‹µë³€ ìƒì„± ì‹œê°„ ì²´í¬
    while (time.time() - start_time < 4.5):
        if not response_queue.empty():
            # 3.5ì´ˆ ì•ˆì— ë‹µë³€ì´ ì™„ì„±ë˜ë©´ ë°”ë¡œ ê°’ ë¦¬í„´
            response = response_queue.get()
            run_flag= True
            break
        # ì•ˆì •ì ì¸ êµ¬ë™ì„ ìœ„í•œ ë”œë ˆì´ íƒ€ì„ ì„¤ì •
        time.sleep(0.01)

    # 3.5ì´ˆ ë‚´ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš°
    if run_flag== False:     
        response = timeover()

    return response


# ë‹µë³€/ì‚¬ì§„ ìš”ì²­ ë° ì‘ë‹µ í™•ì¸ í•¨ìˆ˜
def responseOpenAI(request,response_queue,filename):
    # ì‚¬ìš©ìë‹¤ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹µë³€ ì™„ì„± ì—¬ë¶€ë¥¼ ë‹¤ì‹œ ë´¤ì„ ì‹œ
    if 'ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?' in request["userRequest"]["utterance"]:
        # í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°
        with open(filename) as f:
            last_update = f.read()
        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ ì €ì¥ëœ ì •ë³´ê°€ ìˆì„ ê²½ìš°
        if len(last_update.split())>1:
            kind = last_update.split()[0]  
            if kind == "img":
                print("kkk")
            else:
                bot_res = last_update[4:]
                response_queue.put(textResponseFormat(bot_res))
            dbReset(filename)


            
    #ChatGPT ë‹µë³€ì„ ìš”ì²­í•œ ê²½ìš°
    else:
        # # ê¸°ë³¸ response ê°’
        # base_response = {'version': '2.0', 'template': {'outputs': [], 'quickReplies': []}}
        # response_queue.put(base_response)
        bot_res = getTextFromGPT(request["userRequest"]["utterance"])
        response_queue.put(textResponseFormat(bot_res))

        save_log = "ask"+ " " + str(bot_res)
        with open(filename, 'w') as f:
            f.write(save_log)
