###### ê¸°ë³¸ ì •ë³´ ì„¤ì • ë‹¨ê³„ #######
from fastapi import Request, FastAPI, BackgroundTasks
import openai
import threading
import time
import queue as q
import os


from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain.vectorstores.chroma import Chroma
import streamlit as st
import time
from langchain.document_loaders import PyPDFLoader
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.agents.agent_toolkits import create_retriever_tool
from langchain.chat_models import ChatOpenAI
from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (
    AgentTokenBufferMemory,
)

from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.agents.conversational_chat.base import ConversationalChatAgent
from langchain.schema.messages import SystemMessage
from langchain.prompts import MessagesPlaceholder
from langchain.agents import AgentExecutor
from langchain.memory import ConversationBufferMemory

from loader import Loader



###### ì„œë²„ ìƒì„± ë‹¨ê³„ #######
app = FastAPI()

@app.get("/")
async def root():
    return {"message": "kakaoTest"}

@app.post("/chat/")
async def chat(request: Request):
    kakaorequest = await request.json()
    # print(kakaorequest)
    # return
    return mainChat(kakaorequest)


###### ì¹´ì¹´ì˜¤í†¡ ì‘ë‹µ í•¨ìˆ˜ ######
# ë©”ì„¸ì§€ ì „ì†¡
def textResponseFormat(bot_response):
    response = {'version': '2.0', 'template': {
    'outputs': [{"simpleText": {"text": bot_response}}], 'quickReplies': []}}
    return response

# ì‘ë‹µ ì´ˆê³¼ì‹œ ë‹µë³€
def timeover():
    response = {"version":"2.0","template":{
      "outputs":[
         {
            "simpleText":{
               "text":"ì•„ì§ ì œê°€ ìƒê°ì´ ëë‚˜ì§€ ì•Šì•˜ì–´ìš”ğŸ™ğŸ™\nì ì‹œí›„ ì•„ë˜ ë§í’ì„ ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”ğŸ‘†"
            }
         }
      ],
      "quickReplies":[
         {
            "action":"message",
            "label":"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?ğŸ™‹",
            "messageText":"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?"
         }]}}
    return response


# ë©”ì¸ í•¨ìˆ˜
def mainChat(kakaorequest):

    start_time = time.time()

    # ì‘ë‹µ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    cwd = os.getcwd()
    filename = cwd + '/botlog.txt'
    if not os.path.exists(filename):
        with open(filename, "w") as f:
            f.write("")
    else:
        print("File Exists")    

    # ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰
    response_queue = q.Queue()
    request_respond = threading.Thread(target=responseOpenAI,
                                        args=(kakaorequest, response_queue,filename))
    request_respond.start()

    # ë‹µë³€ ìƒì„± ì‹œê°„ ì²´í¬
    while (time.time() - start_time < 3.5):
        if not response_queue.empty():
            # 3.5ì´ˆ ì•ˆì— ë‹µë³€ì´ ì™„ì„±ë˜ë©´ ë°”ë¡œ ê°’ ë¦¬í„´
            response = response_queue.get()
            run_flag= True
            break
        # ì•ˆì •ì ì¸ êµ¬ë™ì„ ìœ„í•œ ë”œë ˆì´ íƒ€ì„ ì„¤ì •
        time.sleep(0.01)

    # 3.5ì´ˆ ë‚´ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš°
    if run_flag== False:     
        response = timeover()

    return response

# ë‹µë³€/ì‚¬ì§„ ìš”ì²­ ë° ì‘ë‹µ í™•ì¸ í•¨ìˆ˜
def responseOpenAI(request,response_queue,filename):
    